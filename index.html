<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>Reasoning over Scientific Plots</title><meta name="description" content="PlotQA: Reasoning over Scientific Plots"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/PlotQA/logo.png"><link rel="shortcut icon" href="/PlotQA/favicon.ico" type="image/x-icon"><link rel="icon" href="/PlotQA/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/PlotQA/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/PlotQA/stylesheets/layout.css"><link rel="stylesheet" href="/PlotQA/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/PlotQA/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/PlotQA/">Home</a></li><li><a href="/PlotQA/explore/1.0/test/">PlotQA examples</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/PlotQA/">PlotQA</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle"><b>PlotQA</b></h1><h2 id="appSubtitle">Reasoning over Scientific Plots</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is PlotQA?</h2></div><p> <span> </span>PlotQA is a VQA dataset with 28.9 million question-answer pairs grounded over 224,377 plots on data from real-world sources and questions based on crowd-sourced question templates. </p><div class="infoHeadline"><h2>Why PlotQA?</h2></div><p> <span> </span>Existing synthetic datasets (<a href="https://arxiv.org/pdf/1710.07300.pdf">FigureQA</a>, <a href="https://arxiv.org/pdf/1801.08163.pdf">DVQA</a>) for reasoning over plots do not contain variability in data labels, real-valued data, or complex reasoning questions. Consequently, proposed models for these datasets do not fully address the challenge of reasoning over plots. In particular, they assume that the answer comes either from a small fixed size vocabulary or from a bounding box within the image. However, in practice this is an unrealistic assumption because many questions require reasoning and thus have real valued answers which appear neither in a small fixed size vocabulary nor in the image. In this work, we aim to bridge this gap between existing datasets and real world plots by introducing PlotQA. Further, 80.76% of the out-of-vocabulary (OOV) questions in PlotQA have answers that are not in a fixed vocabulary.             <!-- a.btn.actionBtn(href="/PlotQA/explore/1.0/test/") Explore PlotQA --><a class="btn actionBtn" href="https://arxiv.org/pdf/1909.00997.pdf">PlotQA paper (WACV 2020)</a></p><hr><div class="infoHeadline"><h2>Getting Started</h2></div><p> Download the dataset of 28.9 million question-answer pairs grounded over 224,377 plots. <ul class="list-unstyled"><li><a class="btn actionBtn" href="https://drive.google.com/drive/folders/1hCMwlZtxqu4-rxD5ja-lUUizOJfuNUfD?usp=sharing" download>Plot Images</a></li><li><a class="btn actionBtn" href="https://drive.google.com/drive/folders/1dwhZUp5vZQSRq0zanCacPB81kFhV6SfG?usp=sharing" download>Annotations</a></li><li><a class="btn actionBtn" href="https://drive.google.com/drive/folders/1Sh79vd9AgwnUk0QAzHMBxd1jXJW3KayQ?usp=sharing" download>QA Pairs</a></li></ul></p><hr><div class="infoHeadline"><h2>PlotQA Pipeline</h2><p> </p><span>Our proposed pipeline (VOES) consists of various subtasks: (i) detect all the elements in the plot (bars, legend names, tick labels, etc), (ii) reads the values of these elements, (iii) establish relationship between the plot elements, and (iv) reason over this structured data.</span><ul class="list-unstyled"><li><a class="btn actionBtn" href="https://github.com/NiteshMethani/PlotQA/blob/master/PlotQA_Pipeline.md" download>Download Code</a></li><li></li></ul></div><div class="infoHeadline"><h2>Have Questions?</h2></div><p> Ask us questions at   <a href="mailto:nmethani@cse.iitm.ac.in">nmethani@cse.iitm.ac.in</a> and <a href="mailto:prithag@cse.iitm.ac.in">prithag@cse.iitm.ac.in</a>.</p><div class="infoHeadline"><h2>Acknowledgements</h2></div><p> Thank you <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a>
for allowing us to use the code to create this website.</p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://iitmnlp.github.io/PlotQA/" data-text="The PlotQA Dataset - Reasoning over Scientific Plots" data-via="iitmnlp" data-size="large" data-hashtags="PlotQA">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/iitmnlp/PlotQA" data-icon="octicon-star" data-style="mega" data-count-href="/iitmnlp/PlotQA/stargazers" data-count-api="/repos/iitmnlp/PlotQA#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star iitmnlp/PlotQA on GitHub">Star</a></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Results (trained and tested on PlotQA)</h2></div><p>To assess the difficulty of the PlotQA dataset, we report human accuracy on a small subset of the Test split of the dataset. We also evaluate three state-of-the-art models on PlotQA and observe that uur proposed hybrid model significantly outperforms the existing models. It has an aggregate accuracy of 22.52% on the PlotQA dataset. We acknowledge that the accuracy is significantly lower than human performance. This establishes that the dataset is challenging and raises open questions on models for visual reasoning.</p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>Accuracy</th></tr><tr><td><p></p><span class="date label label-default"></span></td><td>Human Baseline <p class="institution">IIT Madras</p></td><td>80.47</td></tr><tr><td><p>1</p><span class="date label label-default">March, 2020</span></td><td>Hybrid Model <b><p class="institution">IIT Madras</p><a href="https://arxiv.org/pdf/1909.00997.pdf">(Methani & al. '20)</a></td><td>22.52</td></tr><tr><td><p>2</p><span class="date label label-default">March, 2020</span></td><td>VOES <b><p class="institution">IIT Madras</p><a href="https://arxiv.org/pdf/1909.00997.pdf">(Methani & al. '20)</a></td><td>18.46</td></tr><tr><td><p>3</p><span class="date label label-default">March, 2020</span></td><td>SAN <b><p class="institution">Carnegie Mellon University</p><a href="https://arxiv.org/pdf/1511.02274.pdf">(Yang & al., '16)</a></td><td>7.76</td></tr></table></div></div><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Results (trained and tested on DVQA)</h2></div><p>  We evaluate our model on the test-set of DVQA. Our proposed hybrid model performs better than the existing models (SAN and SANY-OCR) establishing a new state-of-the-art result on DVQA.</p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>Accuracy      </th><tr><td><p>1</p><span class="date label label-default">March, 2020</span></td><td>Hybrid Model <b><p class="institution">IIT Madras</p><a href="https://arxiv.org/pdf/1909.00997.pdf">(Methani & al. '20)</a></td><td>57.99</td></tr><tr><td><p>2</p><span class="date label label-default">March, 2020</span></td><td>SANDY-OCR <b><p class="institution">Rochester Institute of Technology</p><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.pdf">(Kafle et al., 2018)</a></td><td>45.77</td></tr><tr><td><p>3</p><span class="date label label-default">March, 2020</span></td><td>SAN <b><p class="institution">Carnegie Mellon University</p><a href="https://arxiv.org/pdf/1511.02274.pdf">(Yang & al., '16)</a></td><td>32.1</td></tr></tr></table></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="rightNav"><div><ul class="nav navbar-nav navbar-right"><li><a href="https://github.com/iitmnlp">IIT Madras NLP</a></li></ul></div></div></div></nav><script src="/PlotQA/bower_components/jquery/dist/jquery.min.js"></script><script src="/PlotQA/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>